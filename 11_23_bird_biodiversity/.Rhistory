install.packages("lubridate")
install.packages("tidyverse")
install.packages("descr")
install.packages("Hmisc")
installed.packages("vegan")
installed.packages("dplyr")
install.packages("colorspace")
setwd("~/Documents/GitHub/research_redlining_biodiversity")
data<- read.delim("~/Documents/GitHub/research_redlining_biodiversity/data/ebd_US-GA-089_202001_202012_relMar-2022.txt")
data<- read.delim("~/Documents/GitHub/research_redlining_biodiversity/data/ebd_US-GA-089_202001_202012_relMar-2022.txt")
data$OBSERVATION_DATE <- as.Date(data2018$OBSERVATION.DATE, format="%Y-%m-%d")
data$OBSERVATION_DATE <- as.Date(data$OBSERVATION.DATE, format="%Y-%m-%d")
data$YEAR <- year(data$OBSERVATION.DATE)
data$OBSERVATION_DATE <- as.Date(data$OBSERVATION.DATE, format="%Y-%m-%d")
data$YEAR <- year(data$OBSERVATION.DATE)
library(auk)
library(lubridate)
library(sf)
library(gridExtra)
library(tidyverse)
library(descr)
library(Hmisc)
library(vegan)
install.packages("auk")
install.packages("sf")
install.packages("gridExtra")
install.packages("lubridate")
install.packages("tidyverse")
install.packages("descr")
install.packages("Hmisc")
installed.packages("vegan")
installed.packages("dplyr")
install.packages("colorspace")
install.packages("auk")
library(auk)
library(lubridate)
library(sf)
library(gridExtra)
library(tidyverse)
library(descr)
library(Hmisc)
library(vegan)
install.packages("vegan")
install.packages("dplyr")
install.packages("dplyr")
library(vegan)
library(dplyr)
data$OBSERVATION_DATE <- as.Date(data$OBSERVATION.DATE, format="%Y-%m-%d")
data$YEAR <- year(data$OBSERVATION.DATE)
library(lubridate)
data$YEAR <- year(data$OBSERVATION.DATE)
sampling_event_info <- data2018 %>%
select(SAMPLING.EVENT.IDENTIFIER, LOCALITY, LOCALITY.ID, OBSERVATION.DATE,
PROTOCOL.TYPE, ALL.SPECIES.REPORTED, EFFORT.DISTANCE.KM, EFFORT.AREA.HA,
DURATION.MINUTES, YEAR, GROUP.IDENTIFIER, LATITUDE, LONGITUDE) %>%
distinct()
sampling_event_info <- data %>%
select(SAMPLING.EVENT.IDENTIFIER, LOCALITY, LOCALITY.ID, OBSERVATION.DATE,
PROTOCOL.TYPE, ALL.SPECIES.REPORTED, EFFORT.DISTANCE.KM, EFFORT.AREA.HA,
DURATION.MINUTES, YEAR, GROUP.IDENTIFIER, LATITUDE, LONGITUDE) %>%
distinct()
X_missing <- data %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(number_X = sum(OBSERVATION.COUNT=="X"))
data_clean <- data %>%
filter(CATEGORY %in% c("species","issf")) %>%
group_by(SAMPLING.EVENT.IDENTIFIER, COMMON.NAME) %>%
summarise(COUNT.SPP = sum(as.numeric(as.character(OBSERVATION.COUNT)))) %>%
rename(OBSERVATION.COUNT = COUNT.SPP) %>%
inner_join(., sampling_event_info, by="SAMPLING.EVENT.IDENTIFIER")%>%
inner_join(., X_missing, by="SAMPLING.EVENT.IDENTIFIER")
warnings()
analysis_data <- data_clean %>%
## filter for only complete checklists
filter(ALL.SPECIES.REPORTED == 1)
analysis_data <- analysis_data  %>% filter(PROTOCOL.TYPE %in% c("Area", "Stationary", "Traveling"))
analysis_data <- analysis_data  %>%   filter(number_X==0) %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(Species_Richness=length(unique(COMMON.NAME)),
Species_Diversity=diversity(OBSERVATION.COUNT),
Species_Abundance=sum(OBSERVATION.COUNT, na.rm=TRUE),
Minutes=mean(DURATION.MINUTES, na.rm=TRUE),
Distance_km=mean(EFFORT.DISTANCE.KM, na.rm=TRUE),
Area_ha=mean(EFFORT.AREA.HA, na.rm=TRUE)) %>%
inner_join(data2018_clean, ., by="SAMPLING.EVENT.IDENTIFIER")%>%
## Filter between 2010 and 2020-- not always necessary, but part of the larger code
filter(YEAR>= 2010 & YEAR <= 2020)
analysis_data <- analysis_data  %>%   filter(number_X==0) %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(Species_Richness=length(unique(COMMON.NAME)),
Species_Diversity=diversity(OBSERVATION.COUNT),
Species_Abundance=sum(OBSERVATION.COUNT, na.rm=TRUE),
Minutes=mean(DURATION.MINUTES, na.rm=TRUE),
Distance_km=mean(EFFORT.DISTANCE.KM, na.rm=TRUE),
Area_ha=mean(EFFORT.AREA.HA, na.rm=TRUE)) %>%
inner_join(data_clean, ., by="SAMPLING.EVENT.IDENTIFIER")%>%
## Filter between 2010 and 2020-- not always necessary, but part of the larger code
filter(YEAR>= 2010 & YEAR <= 2020)
duplicated <- analysis_data %>%
drop_na(GROUP.IDENTIFIER) %>%
select(GROUP.IDENTIFIER, SAMPLING.EVENT.IDENTIFIER) %>%
distinct(.keep_all=TRUE) %>%
group_by(GROUP.IDENTIFIER) %>%
# randomly sample one checklist for each group_identifier
sample_n(., 1) %>%
.$SAMPLING.EVENT.IDENTIFIER
duplicated_data <- analysis_data %>%
filter(SAMPLING.EVENT.IDENTIFIER %in% duplicated)
install.packages("tidyr")
library(tidyr)
duplicated <- analysis_data %>%
drop_na(GROUP.IDENTIFIER) %>%
select(GROUP.IDENTIFIER, SAMPLING.EVENT.IDENTIFIER) %>%
distinct(.keep_all=TRUE) %>%
group_by(GROUP.IDENTIFIER) %>%
# randomly sample one checklist for each group_identifier
sample_n(., 1) %>%
.$SAMPLING.EVENT.IDENTIFIER
duplicated_data <- analysis_data %>%
filter(SAMPLING.EVENT.IDENTIFIER %in% duplicated)
nalysis_data <- analysis_data %>%
filter(!grepl("G", GROUP.IDENTIFIER)) %>%
bind_rows(., duplicated_data)
analysis_data <- analysis_data %>%
filter(DURATION.MINUTES >= 5 & DURATION.MINUTES <=240) %>%
filter(EFFORT.DISTANCE.KM <= 10)
analysis_data.all <- analysis_data
checklists_hotspots <- analysis_data.all%>%
group_by(LOCALITY.ID)%>%
summarise(total_checklists=length(unique(SAMPLING.EVENT.IDENTIFIER)))
analysis_data.95 <- analysis_data.all%>%
group_by(LOCALITY.ID, COMMON.NAME)%>%
summarise(species_count=length(COMMON.NAME))%>%
inner_join(checklists_hotspots, ., by="LOCALITY.ID")%>%
mutate(percentage_of_checklists=(species_count/total_checklists)*100)%>%
inner_join(analysis_data.all, ., by=c("LOCALITY.ID", "COMMON.NAME"))%>%
filter(percentage_of_checklists >=5.00) ## removing species that are on < 5% of checklists in a hotspot
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.95 <- as_date(analysis_data.95$OBSERVATION.DATE)
analysis_data.95 <- analysis_data.95 %>%
mutate(
month = month(OBSERVATION.DATE),
day_of_year = yday(OBSERVATION.DATE))
library(dplyr)
analysis_data.95 <- analysis_data.95 %>%
mutate(
month = month(OBSERVATION.DATE),
day_of_year = yday(OBSERVATION.DATE))
analysis_data.95 <- as_date(analysis_data.95$OBSERVATION.DATE)
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.95 <- analysis_data.all%>%
group_by(LOCALITY.ID, COMMON.NAME)%>%
summarise(species_count=length(COMMON.NAME))%>%
inner_join(checklists_hotspots, ., by="LOCALITY.ID")%>%
mutate(percentage_of_checklists=(species_count/total_checklists)*100)%>%
inner_join(analysis_data.all, ., by=c("LOCALITY.ID", "COMMON.NAME"))%>%
filter(percentage_of_checklists >=5.00) ## removing species that are on < 5% of checklists in a hotspot
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.95 <- as_date(analysis_data.95$OBSERVATION.DATE)
analysis_data.95 <- analysis_data.95 %>%
mutate(
month = month(OBSERVATION.DATE),
day_of_year = yday(OBSERVATION.DATE))
analysis_data.95 <- analysis_data.95 %>%
format(
"month" = (OBSERVATION.DATE))
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.95 <- analysis_data.all%>%
group_by(LOCALITY.ID, COMMON.NAME)%>%
summarise(species_count=length(COMMON.NAME))%>%
inner_join(checklists_hotspots, ., by="LOCALITY.ID")%>%
mutate(percentage_of_checklists=(species_count/total_checklists)*100)%>%
inner_join(analysis_data.all, ., by=c("LOCALITY.ID", "COMMON.NAME"))%>%
filter(percentage_of_checklists >=5.00) ## removing species that are on < 5% of checklists in a hotspot
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.all <- as_date(analysis_data.95$OBSERVATION.DATE)
analysis_data.all <- analysis_data.95 %>%
mutate(
month = month(OBSERVATION.DATE),
day_of_year = yday(OBSERVATION.DATE))
analysis_data.all <- analysis_data.all %>% mutate(season =
case_when(month == 1 ~ "W",
month == 2 ~ "W",
month == 3 ~ "Sp",
month == 4 ~ "Sp",
month == 5 ~ "Sp",
month == 6 ~ "Su",
month == 7 ~ "Su",
month == 8 ~ "Su",
month == 9 ~ "F",
month == 10 ~ "F",
month == 11 ~ "F",
month == 12 ~ "W")
)
colnames(analysis_data.all)
brd_matrix<- analysis_data.all %>% group_by(SAMPLING.EVENT.IDENTIFIER, COMMON.NAME) %>%
summarise(count=n()) %>%
spread(COMMON.NAME,count)
brd_matrix[is.na(brd_matrix)] <- 0
colnames(analysis_data.all)
brd_matrix<- analysis_data.all %>% group_by(SAMPLING.EVENT.IDENTIFIER, COMMON.NAME) %>%
summarise(count=n()) %>%
spread(COMMON.NAME,count)
brd_matrix[is.na(brd_matrix)] <- 0
# Look at it - does it look ok?
brd_matrix
subSEI <- subset (brd_matrix, select = "SAMPLING.EVENT.IDENTIFIER")
### Need
brd_matrix <- brd_matrix[,-1]
rich <- specnumber(brd_matrix, MARGIN = 1)
shannondiv <- diversity(brd_matrix, MARGIN = 1)
##Need to take richness list and make it a dataframe
rich_df <- enframe(rich, name = NULL, value= "value")
library(tidyr)
shan_df <- enframe(shannondiv, name = NULL, value= "value")
library(tidyr)
##Need to take richness list and make it a dataframe
shan_df <- enframe(shannondiv, name = NULL, value= "value")
library(tidyr)
library(dplyr)
rich_df <- enframe(rich, name = NULL, value= "value")
library(tidyverse)
shan_df <- enframe(shannondiv, name = NULL, value= "value")
shan_df <- shan_df %>% rename (shannon = value)
shan_df <- cbind (shan_df,subSEI)
analysis_data.all<- right_join(shan_df, analysis_data.all)
analysis_data.all<- unique(analysis_data.all) ### Though there should not be any extra rows or duplications at this point so this is probably completely redundant
View(analysis_data.all)
View(brd_matrix)
View(analysis_data.all)
View(analysis_data.all)
View(analysis_data.95)
View(analysis_data.95)
View(data)
View(data)
data<- read.delim("~/Documents/GitHub/research_redlining_biodiversity/data/ebd_US-GA-089_202001_202012_relMar-2022.txt")
colnames(data)
data$OBSERVATION_DATE <- as.Date(data$OBSERVATION.DATE, format="%Y-%m-%d")
data$YEAR <- year(data$OBSERVATION.DATE)
colnames(data)
sampling_event_info <- data %>%
select(SAMPLING.EVENT.IDENTIFIER, LOCALITY, LOCALITY.ID, OBSERVATION.DATE,
PROTOCOL.TYPE, ALL.SPECIES.REPORTED, EFFORT.DISTANCE.KM, EFFORT.AREA.HA,
DURATION.MINUTES, YEAR, GROUP.IDENTIFIER, LATITUDE, LONGITUDE) %>%
distinct()
colnames(sampling_event_info)
X_missing <- data %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(number_X = sum(OBSERVATION.COUNT=="X"))
data_clean <- data %>%
filter(CATEGORY %in% c("species","issf")) %>%
group_by(SAMPLING.EVENT.IDENTIFIER, COMMON.NAME) %>%
summarise(COUNT.SPP = sum(as.numeric(as.character(OBSERVATION.COUNT)))) %>%
rename(OBSERVATION.COUNT = COUNT.SPP) %>%
inner_join(., sampling_event_info, by="SAMPLING.EVENT.IDENTIFIER")%>%
inner_join(., X_missing, by="SAMPLING.EVENT.IDENTIFIER")
View(data_clean)
View(sampling_event_info)
View(data_clean)
View(data)
warnings()
View(data_clean)
View(data_clean)
analysis_data <- data_clean %>%
## filter for only complete checklists
filter(ALL.SPECIES.REPORTED == 1)
View(analysis_data)
analysis_data <- analysis_data  %>% filter(PROTOCOL.TYPE %in% c("Area", "Stationary", "Traveling"))
analysis_data <- analysis_data  %>%   filter(number_X==0) %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(Species_Richness=length(unique(COMMON.NAME)),
Species_Diversity=diversity(OBSERVATION.COUNT),
Species_Abundance=sum(OBSERVATION.COUNT, na.rm=TRUE),
Minutes=mean(DURATION.MINUTES, na.rm=TRUE),
Distance_km=mean(EFFORT.DISTANCE.KM, na.rm=TRUE),
Area_ha=mean(EFFORT.AREA.HA, na.rm=TRUE)) %>%
inner_join(data_clean, ., by="SAMPLING.EVENT.IDENTIFIER")%>%
## Filter between 2010 and 2020-- not always necessary, but part of the larger code
filter(YEAR>= 2010 & YEAR <= 2020)
View(analysis_data)
analysis_data <- analysis_data  %>%   filter(number_X==0) %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(Species_Richness=length(unique(COMMON.NAME)),
Species_Diversity=diversity(OBSERVATION.COUNT),
Species_Abundance=sum(OBSERVATION.COUNT, na.rm=TRUE),
Minutes=mean(DURATION.MINUTES, na.rm=TRUE),
Distance_km=mean(EFFORT.DISTANCE.KM, na.rm=TRUE),
Area_ha=mean(EFFORT.AREA.HA, na.rm=TRUE)) %>%
inner_join(data_clean, ., by="SAMPLING.EVENT.IDENTIFIER")%>%
## Filter between 2010 and 2020-- not always necessary, but part of the larger code
filter(YEAR>= 2010 & YEAR <= 2020)
View(analysis_data)
duplicated <- analysis_data %>%
drop_na(GROUP.IDENTIFIER) %>%
select(GROUP.IDENTIFIER, SAMPLING.EVENT.IDENTIFIER) %>%
distinct(.keep_all=TRUE) %>%
group_by(GROUP.IDENTIFIER) %>%
# randomly sample one checklist for each group_identifier
sample_n(., 1) %>%
.$SAMPLING.EVENT.IDENTIFIER
duplicated_data <- analysis_data %>%
filter(SAMPLING.EVENT.IDENTIFIER %in% duplicated)
analysis_data <- analysis_data %>%
filter(!grepl("G", GROUP.IDENTIFIER)) %>%
bind_rows(., duplicated_data)
analysis_data <- analysis_data %>%
filter(DURATION.MINUTES >= 15 & DURATION.MINUTES <=240) %>%
filter(EFFORT.DISTANCE.KM <= 10)
analysis_data.all <- analysis_data
checklists_hotspots <- analysis_data.all%>%
group_by(LOCALITY.ID)%>%
summarise(total_checklists=length(unique(SAMPLING.EVENT.IDENTIFIER)))
analysis_data.95 <- analysis_data.all%>%
group_by(LOCALITY.ID, COMMON.NAME)%>%
summarise(species_count=length(COMMON.NAME))%>%
inner_join(checklists_hotspots, ., by="LOCALITY.ID")%>%
mutate(percentage_of_checklists=(species_count/total_checklists)*100)%>%
inner_join(analysis_data.all, ., by=c("LOCALITY.ID", "COMMON.NAME"))%>%
filter(percentage_of_checklists >=5.00) ## removing species that are on < 5% of checklists in a hotspot
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.all <- as_date(analysis_data.95$OBSERVATION.DATE)
analysis_data.all <- analysis_data.95 %>%
mutate(
month = month(OBSERVATION.DATE),
day_of_year = yday(OBSERVATION.DATE))
### Dates to Seasons
analysis_data.all <- analysis_data.all %>% mutate(season =
case_when(month == 1 ~ "W",
month == 2 ~ "W",
month == 3 ~ "Sp",
month == 4 ~ "Sp",
month == 5 ~ "Sp",
month == 6 ~ "Su",
month == 7 ~ "Su",
month == 8 ~ "Su",
month == 9 ~ "F",
month == 10 ~ "F",
month == 11 ~ "F",
month == 12 ~ "W")
)
community_by_observation <- analysis.data.all
community_by_observation <- analysis_data.all
colnames(community_by_observation)
View(analysis_data)
View(community_by_observation)
View(checklists_hotspots)
location <- subset(community_by_observation, select= c("SAMPLING.EVENT.IDENTIFIER", "LOCALITY.ID", "LATITUDE", "LONGITUDE", "Species_Richness", "Species_Diversity","Species_Abundance" ))
location <- unique(location)
View(location)
install.packages("tidycensus")
install.packages("tidyverse")
install.packages("sf")
install.packages("tidycensus")
install.packages("tidyverse")
install.packages("sf")
install.packages("RColorBrewer")
install.packages("mapview")
install.packages("mapview")
library(tidycensus)
library(tidyverse)
library(sf)
library(RColorBrewer)
library(mapview)
library(ggplot2)
census_api_key("ca98ed282d04f9e94ec09dbcccbf7583fcb703a7", install=TRUE, overwrite = TRUE)
readRenviron("~/.Renviron")
poverty <- get_acs(
state = 'GA', # Georgia state FIPS code is '13'
county = 'DeKalb', # Specify the county name
geography = 'tract',
year = 2019, # 2015-2019 5-year ACS
geometry = TRUE,
variables = c(
in_poverty = 'B05010_002E',
total_pop_for_poverty_estimates = 'B05010_001E'
)
)
library(auk)
library(lubridate)
library(sf)
library(gridExtra)
library(tidyverse)
library(descr)
library(Hmisc)
library(vegan)
library(dplyr)
library(tidyr)
setwd("~/Documents/GitHub/research_redlining_biodiversity")
###eBird data is downloaded directly for each county
data<- read.delim("~/Documents/GitHub/research_redlining_biodiversity/data/ebd_US-GA-089_202001_202012_relMar-2022.txt")
colnames(data)
#####Appendix code
# Format Date
data$OBSERVATION_DATE <- as.Date(data$OBSERVATION.DATE, format="%Y-%m-%d")
# add year to the dataframe
data$YEAR <- year(data$OBSERVATION.DATE)
colnames(data)
# add all the columns needed for the analysis (that don't vary within checklist)
sampling_event_info <- data %>%
select(SAMPLING.EVENT.IDENTIFIER, LOCALITY, LOCALITY.ID, OBSERVATION.DATE,
PROTOCOL.TYPE, ALL.SPECIES.REPORTED, EFFORT.DISTANCE.KM, EFFORT.AREA.HA,
DURATION.MINUTES, YEAR, GROUP.IDENTIFIER, LATITUDE, LONGITUDE) %>%
distinct()
colnames(sampling_event_info)
# Counts how many 'x's per checklist
X_missing <- data %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(number_X = sum(OBSERVATION.COUNT=="X"))
# accounts for the instance in which people submit
# the same species both at the species and subspecies level
# also makes it so only 'species' and 'issf' category are included in analysis
##joins the sampling_event_info and the X_missing data all into one dataframe
data_clean <- data %>%
filter(CATEGORY %in% c("species","issf")) %>%
group_by(SAMPLING.EVENT.IDENTIFIER, COMMON.NAME) %>%
summarise(COUNT.SPP = sum(as.numeric(as.character(OBSERVATION.COUNT)))) %>%
rename(OBSERVATION.COUNT = COUNT.SPP) %>%
inner_join(., sampling_event_info, by="SAMPLING.EVENT.IDENTIFIER")%>%
inner_join(., X_missing, by="SAMPLING.EVENT.IDENTIFIER")
####NAs introduced by coercion
warnings()
##################################################
##### apply some basic criteria to filter by #####
##################################################
# apply some filtering criteria and join into one big file
analysis_data <- data_clean %>%
## filter for only complete checklists
filter(ALL.SPECIES.REPORTED == 1)
## only using stationary, traveling, and exhaustive area type checklists
analysis_data <- analysis_data  %>% filter(PROTOCOL.TYPE %in% c("Area", "Stationary", "Traveling"))
## Get rid of any checklists that have X and calculate Species Richness, Diversity, and Abundance
analysis_data <- analysis_data  %>%   filter(number_X==0) %>%
group_by(SAMPLING.EVENT.IDENTIFIER) %>%
summarise(Species_Richness=length(unique(COMMON.NAME)),
Species_Diversity=diversity(OBSERVATION.COUNT),
Species_Abundance=sum(OBSERVATION.COUNT, na.rm=TRUE),
Minutes=mean(DURATION.MINUTES, na.rm=TRUE),
Distance_km=mean(EFFORT.DISTANCE.KM, na.rm=TRUE),
Area_ha=mean(EFFORT.AREA.HA, na.rm=TRUE)) %>%
inner_join(data_clean, ., by="SAMPLING.EVENT.IDENTIFIER")%>%
## Filter between 2010 and 2020-- not always necessary, but part of the larger code
filter(YEAR>= 2010 & YEAR <= 2020)
##############################################################################
## filtering out group_identifier data to eliminate 'duplicated' checklists ##
##############################################################################
# first select the group_identifiers and associated checklists
duplicated <- analysis_data %>%
drop_na(GROUP.IDENTIFIER) %>%
select(GROUP.IDENTIFIER, SAMPLING.EVENT.IDENTIFIER) %>%
distinct(.keep_all=TRUE) %>%
group_by(GROUP.IDENTIFIER) %>%
# randomly sample one checklist for each group_identifier
sample_n(., 1) %>%
.$SAMPLING.EVENT.IDENTIFIER
duplicated_data <- analysis_data %>%
filter(SAMPLING.EVENT.IDENTIFIER %in% duplicated)
## now, append the selected checklists for each group_identifier
## with the non group_identifier checklists from the data
analysis_data <- analysis_data %>%
filter(!grepl("G", GROUP.IDENTIFIER)) %>%
bind_rows(., duplicated_data)
#########################################################
############ apply distance and duration caps ###########
#########################################################
analysis_data <- analysis_data %>%
filter(DURATION.MINUTES >= 15 & DURATION.MINUTES <=240) %>%
filter(EFFORT.DISTANCE.KM <= 10)
## rename analysis_data to signify it is the 'complete' checklist usage
analysis_data.all <- analysis_data
######################################################################
#### get rid of species which did not occur on >95% of checklists ####
######################################################################
## Exclude the species that rarely occur
checklists_hotspots <- analysis_data.all%>%
group_by(LOCALITY.ID)%>%
summarise(total_checklists=length(unique(SAMPLING.EVENT.IDENTIFIER)))
## create a dataframe which removes the species that are on <=5% of checklists in a hotspot
analysis_data.95 <- analysis_data.all%>%
group_by(LOCALITY.ID, COMMON.NAME)%>%
summarise(species_count=length(COMMON.NAME))%>%
inner_join(checklists_hotspots, ., by="LOCALITY.ID")%>%
mutate(percentage_of_checklists=(species_count/total_checklists)*100)%>%
inner_join(analysis_data.all, ., by=c("LOCALITY.ID", "COMMON.NAME"))%>%
filter(percentage_of_checklists >=5.00) ## removing species that are on < 5% of checklists in a hotspot
### Wanting to just add a few details that may be important later in analysis....maybe.
###Using the analysis that removed the rarest species
analysis_data.95$OBSERVATION.DATE <- ymd(analysis_data.95$OBSERVATION.DATE)
analysis_data.all <- as_date(analysis_data.95$OBSERVATION.DATE)
analysis_data.all <- analysis_data.95 %>%
mutate(
month = month(OBSERVATION.DATE),
day_of_year = yday(OBSERVATION.DATE))
### Dates to Seasons
analysis_data.all <- analysis_data.all %>% mutate(season =
case_when(month == 1 ~ "W",
month == 2 ~ "W",
month == 3 ~ "Sp",
month == 4 ~ "Sp",
month == 5 ~ "Sp",
month == 6 ~ "Su",
month == 7 ~ "Su",
month == 8 ~ "Su",
month == 9 ~ "F",
month == 10 ~ "F",
month == 11 ~ "F",
month == 12 ~ "W")
)
community_by_observation <- analysis_data.all
### So now create a dataframe that is just the locality id, lat, long, species richness, shannon's, & abundance
colnames(community_by_observation)
location <- subset(community_by_observation, select= c("SAMPLING.EVENT.IDENTIFIER", "LOCALITY.ID", "LATITUDE", "LONGITUDE", "Species_Richness", "Species_Diversity","Species_Abundance" ))
location <- unique(location)
